from django.test import TestCase

class BLEOBaseTest(TestCase):
    """Base test class with enhanced logging for all BLEO tests"""
    
    def setUp(self):
        # This runs before each test
        self.test_name = self._testMethodName
        print(f"\nüìã Running test: {self.test_name}")
    
    def tearDown(self):
        # This runs after each test
        test_method = getattr(self, self._testMethodName)
        test_doc = test_method.__doc__ or "No description"
        
        # Check if the test was successful
        if hasattr(self, '_outcome'):  # For Python 3.4+
            result = self._outcome.result
            if result.failures or result.errors:
                for failure in result.failures:
                    if self == failure[0]:
                        error_msg = failure[1].split('\n')[-2] if len(failure) > 1 else "Unknown error"
                        print(f"‚ùå FAILED: {test_doc.strip()} - {error_msg}")
                        return
                for error in result.errors:
                    if self == error[0]:
                        error_msg = error[1].split('\n')[-2] if len(error) > 1 else "Unknown error"
                        print(f"‚ùå ERROR: {test_doc.strip()} - {error_msg}")
                        return
        
        # If we got here, the test passed
        print(f"‚úÖ PASSED: {test_doc.strip()}")


class ColoredOutput:
    """Simple colored output for Windows and Unix systems"""
    
    @staticmethod
    def red(text):
        return f"\033[91m{text}\033[0m"
    
    @staticmethod
    def green(text):
        return f"\033[92m{text}\033[0m"
    
    @staticmethod
    def yellow(text):
        return f"\033[93m{text}\033[0m"
    
    @staticmethod
    def blue(text):
        return f"\033[94m{text}\033[0m"
    
    @staticmethod
    def bold(text):
        return f"\033[1m{text}\033[0m"
    
    @staticmethod
    def cyan(text):
        return f"\033[96m{text}\033[0m"
    
    @staticmethod
    def magenta(text):
        return f"\033[95m{text}\033[0m"


class TestSummaryFormatter:
    """Shared test summary formatting logic"""
    
    @staticmethod
    def show_enhanced_summary(test_results, total_time=None, test_case_name=None):
        """Show the enhanced test summary - used by both runners"""
        print("\n" + "="*80)
        print(ColoredOutput.bold("üìä BLEO TEST EXECUTION SUMMARY"))
        print("="*80)
        
        if test_results:
            total_tests = test_results.testsRun
            failed_tests = len(test_results.failures)
            error_tests = len(test_results.errors)
            passed_tests = total_tests - failed_tests - error_tests
            total_failures = failed_tests + error_tests
            
            # Calculate success rate
            success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
            
            # Overall statistics with enhanced colors
            print(f"\nüìà OVERALL RESULTS:")
            print(f"   Total Tests Run: {ColoredOutput.bold(ColoredOutput.cyan(str(total_tests)))}")
            if total_time:
                print(f"   Execution Time: {ColoredOutput.bold(ColoredOutput.magenta(f'{total_time:.2f} seconds'))}")
            
            if total_failures == 0:
                print(f"   Passed: {ColoredOutput.green(ColoredOutput.bold(f'{passed_tests}/{total_tests}'))}")
                print(f"   Failed: {ColoredOutput.green('0/' + str(total_tests))}")
                print(f"   Success Rate: {ColoredOutput.green(ColoredOutput.bold(f'{success_rate:.1f}%'))}")
                
                # Success celebration
                print(f"\nüéâ {ColoredOutput.green(ColoredOutput.bold('ALL TESTS PASSED!'))}")
                suite_name = test_case_name or 'Test suite'
                print(f"üåü {ColoredOutput.cyan(suite_name)} completed with {ColoredOutput.green(ColoredOutput.bold('100% success rate'))}")
                
                if total_time:
                    print(f"üöÄ {ColoredOutput.magenta(f'Executed {total_tests} test(s) successfully in {total_time:.1f}s')}")
                else:
                    print(f"üöÄ {ColoredOutput.magenta(f'Executed {total_tests} test(s) successfully')}")
                
                # Success tips
                print(f"\n‚ú® EXCELLENCE ACHIEVED:")
                print(f"   ‚Ä¢ All test assertions passed successfully")
                print(f"   ‚Ä¢ No runtime errors encountered")
                print(f"   ‚Ä¢ Code coverage appears to be working correctly")
                print(f"   ‚Ä¢ Ready for deployment or further development")
                
            else:
                print(f"   Passed: {ColoredOutput.green(f'{passed_tests}/{total_tests}')}")
                print(f"   Failed: {ColoredOutput.red(f'{total_failures}/{total_tests}')}")
                print(f"   Success Rate: {ColoredOutput.yellow(f'{success_rate:.1f}%')}")
                
                print(f"\n‚ö†Ô∏è  {ColoredOutput.yellow(f'Some tests failed - Success rate: {success_rate:.1f}%')}")
                suite_name = test_case_name or 'Test suite'
                print(f"üìä {ColoredOutput.cyan(suite_name)} results: {ColoredOutput.green(f'{passed_tests} passed')}, {ColoredOutput.red(f'{total_failures} failed')}")
                
                # Show detailed failure information
                TestSummaryFormatter._show_failure_details(test_results)
                
                # Quick fix suggestions
                print(f"\nüí° QUICK ACTIONS:")
                print(f"   ‚Ä¢ Review failed test cases listed above")
                print(f"   ‚Ä¢ Check assertion conditions and expected vs actual values")
                print(f"   ‚Ä¢ Verify test data setup and database state")
                print(f"   ‚Ä¢ Run individual tests for detailed debugging")
            
            # Final status line
            print("\n" + "="*80)
            if total_failures == 0:
                final_message = f"üöÄ SUCCESS: {passed_tests} tests passed with 100% success rate!"
                print(ColoredOutput.green(ColoredOutput.bold(final_message)))
            else:
                final_message = f"‚ö†Ô∏è  REVIEW NEEDED: {passed_tests} passed, {total_failures} failed ({success_rate:.1f}% success rate)"
                print(ColoredOutput.red(ColoredOutput.bold(final_message)))
            print("="*80)
            
        else:
            # Fallback if no results captured
            if total_time:
                print(f"‚è±Ô∏è  Total execution time: {total_time:.2f} seconds")
            print("‚ÑπÔ∏è  No detailed test results available")
            print("="*80)
    
    @staticmethod
    def _show_failure_details(test_results):
        """Show detailed failure information with line numbers"""
        if test_results.failures:
            print(f"\n‚ùå ASSERTION FAILURES ({len(test_results.failures)}):")
            for i, failure in enumerate(test_results.failures, 1):
                test_name = str(failure[0]).split('(')[0]
                test_class = failure[0].__class__.__name__
                print(f"   {i}. {ColoredOutput.red(f'{test_class}.{test_name}')}")
                
                # Extract error message and line information
                error_lines = failure[1].split('\n')
                
                # Find the file and line number
                file_line_info = None
                assertion_error = None
                
                for line in error_lines:
                    # Look for file and line information
                    if 'File "' in line and 'line ' in line:
                        # Extract file path and line number
                        try:
                            file_part = line.split('File "')[1].split('"')[0]
                            line_part = line.split('line ')[1].split(',')[0]
                            # Get just the filename, not the full path
                            filename = file_part.split('\\')[-1].split('/')[-1]
                            file_line_info = f"{filename}:{line_part}"
                        except:
                            pass
                    
                    # Look for AssertionError
                    if "AssertionError" in line:
                        assertion_error = line.strip().replace("AssertionError: ", "")
                
                # Display the information
                if file_line_info:
                    print(f"      üìç {ColoredOutput.cyan(f'Location: {file_line_info}')}")
                
                if assertion_error:
                    print(f"      üí• {ColoredOutput.yellow(assertion_error)}")
                else:
                    # If no AssertionError line found, show the last meaningful line
                    for line in reversed(error_lines):
                        if line.strip() and not line.strip().startswith('File') and not line.strip().startswith('    '):
                            print(f"      üí• {ColoredOutput.yellow(line.strip())}")
                            break
        
        if test_results.errors:
            print(f"\nüö® RUNTIME ERRORS ({len(test_results.errors)}):")
            for i, error in enumerate(test_results.errors, len(test_results.failures) + 1):
                test_name = str(error[0]).split('(')[0]
                test_class = error[0].__class__.__name__
                print(f"   {i}. {ColoredOutput.red(f'{test_class}.{test_name}')}")
                
                # Extract error message and line information
                error_lines = error[1].split('\n')
                
                # Find the file and line number
                file_line_info = None
                runtime_error = None
                
                for line in error_lines:
                    # Look for file and line information
                    if 'File "' in line and 'line ' in line:
                        try:
                            file_part = line.split('File "')[1].split('"')[0]
                            line_part = line.split('line ')[1].split(',')[0]
                            filename = file_part.split('\\')[-1].split('/')[-1]
                            file_line_info = f"{filename}:{line_part}"
                        except:
                            pass
                    
                    # Look for runtime errors
                    if any(keyword in line for keyword in ["Error:", "Exception:", "ImportError:", "ModuleNotFoundError:"]):
                        runtime_error = line.strip()
                
                # Display the information
                if file_line_info:
                    print(f"      üìç {ColoredOutput.cyan(f'Location: {file_line_info}')}")
                
                if runtime_error:
                    print(f"      üî• {ColoredOutput.yellow(runtime_error)}")
                else:
                    # If no specific error line found, show the last meaningful line
                    for line in reversed(error_lines):
                        if line.strip() and not line.strip().startswith('File') and not line.strip().startswith('    '):
                            print(f"      üî• {ColoredOutput.yellow(line.strip())}")
                            break


# Keep only the standalone runner for direct file execution
def run_test_with_output(test_case):
    """Run a test with custom output handling and detailed summary (for standalone execution)"""
    import unittest
    
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(unittest.makeSuite(test_case))
    
    # Use the shared formatter
    TestSummaryFormatter.show_enhanced_summary(result, test_case_name=test_case.__name__)
    
    return result